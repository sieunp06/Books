- [1.1 데이터 !](#11-데이터-)
- [1.2 데이터 저장소와 분석](#12-데이터-저장소와-분석)
- [1.3 전체 데이터에 질의하기](#13-전체-데이터에-질의하기)
- [1.4 일괄 처리를 넘어서](#14-일괄-처리를-넘어서)
  - [하둡 에코시스템](#하둡-에코시스템)
  - [하둡의 대표적인 4가지 처리 패턴](#하둡의-대표적인-4가지-처리-패턴)
- [1.5 다른 시스템과의 비교](#15-다른-시스템과의-비교)
  - [1.5.1 관계형 데이터베이스 관리 시스템](#151-관계형-데이터베이스-관리-시스템)
  - [1.5.2 그리드 컴퓨팅](#152-그리드-컴퓨팅)

---

> 예전에 사람들은 무거운 것을 끌기 위해 소를 이용했다. 그리고 소 한 마리가 통나무 하나를 움직일 수 없을 때 그 소를 더 키우려 애쓰지 않았다. 우리에게 필요한 것은 커다란 한 대의 컴퓨터가 아니라 매우 많은 컴퓨터로 이루어진 새로운 시스템이다.
> 
> -그레이스 호퍼
> 

## 1.1 데이터 !

우리는 데이터 시대에 살고 있다.

수 많은 곳에서 엄청난 데이터가 만들어지고 있다.

- 뉴욕증권거래소에서는 하루에 4.5테라바이트의 데이터가 발생한다.
- 페이스북은 2,400억 개의 사진을 보유하고 있으며, 매달 7페타바이트 증가한다.
- 계통조사 사이트인 앤서스트리는 약 10페타바이트의 데이터를 저장하고 있다.
- 인터넷 아카이브는 약 18.5페타바이트의 데이터를 저장하고 있다.
- 스위스 제네바에 있는 대형 하드론 입자가속기는 매년 30페타바이트의 데이터를 생산한다.

이런 빅데이터는 저장하고 분석하는 일이 매우 어렵다.

## 1.2 데이터 저장소와 분석

단일 디스크의 데이터를 읽는 데 너무 많은 시간이 걸리고, 심지어 쓰는 것은 더 느리다.

시간을 줄이는 방법은 여러 개의 디스크에서 동시에 데이터를 읽는 것이다.

하지만 여러 개의 디스크에 데이터를 병렬로 쓰거나 읽으려면 몇몇 문제를 고려해야 한다.

1. 하드웨어 장애
    
    많은 하드웨어를 사용할수록 장애가 발생할 확률도 높아진다.
    
    데이터 손실을 막기 위한 일반적인 방법은 데이터를 여러 곳에 복제하는 것이다.
    
    여러 곳에 데이터의 복사본이 보관되어 있으면 시스템에 장애가 발생해도 다른 복사본을 바로 이용할 수 있게 된다.
    
    이와 같은 방식으로 작동하는 것이 **RAID**다. 이때 하둡의 파일시스템인 HDFS와는 조금 다른 접근 방식을 사용한다.
    
2. 분할된 데이터를 대부분의 분석 작업에서 어떤 식으로든 결합해야 한다.
    
    하나의 디스크에서 읽은 데이터를 다른 99개의 디스크에서 읽은 데이터와 결합해야 할수도 있다.
    
    많은 분산 시스템이 다중 출처의 데이터를 병합하는 기능을 제공하지만, 정합성을 지키는 것은 매우 어려운 도전 과제이다.
    
    > **🤔 왜 어려운 과제인가?**
    분산 환경에서는 네트워크 지연, 장애, 시계 불일치 등으로 인해 모든 데이터가 같은 시점, 같은 규칙을 지키게 하는 것이 힘들다.
    특히, “다중 출처 병합”은 각 데이터 출처가 독립적으로 변경될 수 있어, 정확한 순서와 최종 상태를 보장하기 어렵다.
    때문에 분산 시스템에서는 CAP 이론(Consistency, Availabliity, Partition Tolerance)에서 Consistency(일관성) 부분이 항상 트레이드 오프 대상이 된다.
    > 
    
    맵 리듀스는 디스크에서 데이터를 읽고 쓰는 문제를 키-값 쌍의 계산으로 변환된 추상화된 프로그래밍 모델을 제공한다.
    
    즉, 맵과 리듀스로 분리되어 그 둘 사이를 혼합해주는 인터페이스가 존재한다는 것이다.
    

이러한 하둡은 안정적이고 확장성이 높은 저장 및 분석 플랫폼을 제공한다.

## 1.3 전체 데이터에 질의하기

맵리듀스의 접근법은 무차별 대입 방식처럼 보인다.

맵리듀스의 전체가 한 번의 쿼리로 전체나 상당한 규모의 데이터셋을 처리하는 것이기 때문이다.

이는 맵리듀스의 장점이다.

> **맵리듀스 == 일괄 질의 처리기**
> 

전체 데이터셋을 대상으로 비정형 쿼리를 수행하고 합리적인 시간 내에 그 결과를 보여주는 능력을 지니고 있다.

즉, 전체 데이터셋에 대해 분석/집계/가공 작업을 수행하고 결과를 한 번에 반환한다.

> **🤔 비정형 쿼리란?**
사전에 인덱스나 스키마가 엄격히 정해지지 않은, 분석 목적에 맞게 자유롭게 작성하는 쿼리나 연산
ex) 로그 분석, 클릭 데이터 집계, 추천 시스템 데이터 가공
맵 리듀스는 특정 패턴(SQL처럼 정해진 문법)만 지원하는 게 아니라, 사용자가 직접 Map 단계와 Reduce 단계의 로직을 자유롭게 작성해 처리 가능하다.
> 

## 1.4 일괄 처리를 넘어서

맵리듀스의 강점은 기본적으로 일괄 처리 시스템이라는 것이고, 대화형 분석에는 적합하지 않다.

질의를 실행한 후 수 초 이내에 결과를 받는 것은 불가능하다.

일반적으로 질의를 처리하는데 1분 이상 걸리고, 사람들은 결과를 얻을 때까지 기다리기 힘들기 때문에 오프라인 용도로 적합하다고 할 수 있다.

하지만 하둡은 일괄 처리를 넘어서 진화하고 있다.

실제로 ‘하둡’이라는 단어는 HDFS와 맵리듀스만이 아닌 수많은 에코시스템 프로젝트를 지칭한다.

### 하둡 에코시스템

> 분산 컴퓨팅과 대규모 데이터 처리를 위한 기반 시설
> 
1. 핵심 구성 요소 (하둡 코어)
    
    
    | 구성요소 | 역할 |
    | --- | --- |
    | **HDFS** (Hadoop Distributed File System) | 대용량 데이터를 여러 노드에 분산 저장하는 파일 시스템. 장애 시 복제본을 이용해 복구 가능 |
    | **MapReduce** | 데이터를 분산 저장된 위치에서 병렬 처리하는 프로그래밍 모델 |
    | **YARN** (Yet Another Resource Negotiator) | 클러스터 자원(메모리, CPU) 관리 및 작업 스케줄링 |
2. 하둡 에코시스템 확장 도구
    1. 데이터 수집 & 전송
        
        
        | 도구 | 설명 |
        | --- | --- |
        | **Flume** | 실시간 로그 수집(웹 서버 로그 → HDFS로 전송) |
        | **Sqoop** | 관계형 DB ↔ HDFS 간 대량 데이터 이동 (MySQL, Oracle → HDFS) |
        | **Kafka** | 고성능 메시지 큐, 실시간 스트리밍 데이터 전송 |
    2. 데이터 저장 & 관리
        
        
        | 도구 | 설명 |
        | --- | --- |
        | **HBase** | HDFS 위에 구축된 NoSQL 데이터베이스 (실시간 읽기/쓰기 지원) |
        | **Hive** | HDFS 데이터를 SQL처럼 질의 가능 (MapReduce를 SQL로 추상화) |
        | **HCatalog** | Hive 메타데이터 관리 서비스 |
    3. 데이터 처리 & 분석
        
        
        | 도구 | 설명 |
        | --- | --- |
        | **Pig** | 데이터 흐름 스크립트 언어 (MapReduce를 추상화) |
        | **Spark** | 메모리 기반 분산 처리 엔진 (MapReduce보다 빠름, 배치+스트리밍 지원) |
        | **Tez** | DAG 기반의 빠른 실행 엔진 (Hive/Pig 가속화) |
    4. 워크플로우 & 스케일링
        
        
        | 도구 | 설명 |
        | --- | --- |
        | **Oozie** | 하둡 잡(Job) 스케줄링 & 워크플로우 관리 |
        | **Zookeeper** | 분산 환경에서 설정/동기화/메타데이터 관리 |
    5. 데이터 시각화 & 탐색
        
        
        | 도구 | 설명 |
        | --- | --- |
        | **Hue** | 웹 UI로 Hive, Pig, HDFS 탐색 |
        | **Zeppelin** | 노트북 환경에서 Spark/Hive와 연동, 시각화 가능 |

### 하둡의 대표적인 4가지 처리 패턴

1. 대화형 SQL 처리 (Interactive SQL)
    
    > HDFS에 있는 데이터를 SQL처럼 빠르게 질의하는 패턴
    > 
    
    사용자가 질의를 입력하면 즉시 실행하여, 결과를 수 초~수십 초 내에 반환한다.
    
    ex) HDFS에 쌓인 웹 로그 데이터를 대상으로 “어제의 페이지뷰 상위 10개”를 즉시 조회
    
    - **Hive (LLAP 모드)** → 기존 Hive는 느린 배치 처리지만, LLAP로 반응속도 개선
    - **Impala** → HDFS/HBase에서 직접 SQL 실행
    - **Presto** / **Trino** → 메모리 기반 SQL 쿼리 엔진
2. 반복 처리 (Iterative Processing)
    
    > 데이터를 여러 번 반복적으로 읽고 쓰면서 처리하는 패턴
    > 
    
    머신러닝, 그래프 알고리즘처럼 같은 데이터를 수십~수백 번 반복 처리해야 하는 작업에 사용한다.
    
    맵리듀스는 매번 디스크 I/O를 수행해야 하기 때문에 느리지만, 스파크를 사용하면 해결된다.
    
    - **Apache Spark** → RDD(Resilient Distributed Dataset) 기반, 반복 처리 최적화
    - **Apache Giraph** → 그래프 데이터 처리 (PageRank 등)
3. 스트림 처리
    
    > 실시간으로 들어오는 데이터를 지연 없이 처리하는 패턴
    > 
    
    데이터가 실시간으로 들어올 때 처리와 동시에 분석한다.
    
    이때 밀리초~초 단위의 지연 시간이 발생한다.
    
    - **Apache Kafka** → 데이터 스트리밍 파이프라인
    - **Apache Storm** → 실시간 분산 처리
    - **Apache Flink** → 배치 + 실시간 스트림 처리 모두 가능
    - **Spark Streaming** → 마이크로배치 기반 스트리밍
4. 검색 처리 (Search Processing)
    
    > 대량의 비정형 텍스트 데이터에서 빠르게 검색하는 패턴
    > 
    
    HDFS에 저장된 텍스트, 로그, 문서 등을 색인(index)으로 만들어 빠른 검색이 가능하다.
    
    단어 검색, 키워드 분석, 전문 분석에 최적화 되어 있다.
    
    - **Apache Solr** → HDFS 데이터 색인 및 검색
    - **Elasticsearch** → 분산 검색 및 분석 엔진 (Hadoop/Spark와 연계 가능)

## 1.5 다른 시스템과의 비교

### 1.5.1 관계형 데이터베이스 관리 시스템

> 왜 여러 개의 디스크를 가진 데이터베이스를 이용하여 대규모 분석을 수행할 수 없는 것일까?
왜 하둡이 필요한가?
> 

디스크 드라이브는 다음과 같은 특징을 가지고 있다.

**“탐색 시간은 전송 속도보다 발전이 더디다.”**

탐색 = 데이터를 읽거나 쓸 때 디스크의 헤더를 디스크의 특정 위치로 이동시키는 조작

만약 데이터 접근 패턴이 탐색 위주라면 데이터셋의 커다란 부분을 읽거나 쓰는 작업은 전속 속도에 좌우되는 스트리밍 조작보다 더 오래 걸릴 것이다.

반면 데이터베이스에 있는 일부 레코드를 변경하는 작업은 전통적인 B-트리가 적합하다.

즉, 하둡은 전체 데이터 처리에 좋지만, 특정 몇 개 레코드만 빠르게 찾고 수정해야 하는 경우에는 전통적인 B-트리가 더 낫다.

데이터베이스의 상당 부분을 변경할 때 B-트리는 데이터베이스를 재구성하기 위해 Sort/Merge를 사용해야 하므로 맵리듀스보다 효율적이지 못하다.

| 접근 패턴 | 하둡(HDFS, 스트리밍) | 전통 DB(B-트리) |
| --- | --- | --- |
| **전체 데이터 처리** | 매우 빠름 (병렬 처리) | 상대적으로 느림 |
| **일부 레코드 검색/수정** | 느림 (전체 훑음) | 빠름 (인덱스 접근) |
| **장점** | 대규모 배치 처리, 로그 분석, ETL | 빠른 조회·수정, 트랜잭션 |
| **단점** | 랜덤 액세스 비효율 | 대용량 배치 처리 비효율 |

> 🤔 **탐색 위주 접근 패턴이란?**
전체 데이터를 다 읽는 것이 아니라, 필요한 데이터 일부(특정 조건에 맞는 레코드)만 빠르게 찾아보는 경우를 말한다.
이런 경우, 전체 데이터 중 필요한 데이터는 극히 일부기 때문에 데이터 전체를 순차적으로(스트리밍) 읽는 방식은 비효율적이다.
ex) “이 회원 ID에 해당하는 주문 내역만 가져와라.” 처럼 랜덤 액세스 형태.
> 

> 🤔 B-트리와 일부 레코드 변경
전통적인 관계형 데이터베이스는 내부적으로 B-트리나 변형 구조를 사용해 인덱스를 관리한다.
B-트리는 데이터의 특정 부분에만 접근하고 일부 레코드만 수정하는 랜덤 읽기/쓰기에 강하다.
> 

여러 면에서 맵리듀스는 RDBMS를 보완하는 것처럼 보이지만, 차이가 있다.

- 맵리듀스
    
    비정형 분석과 같이 일괄 처리 방식으로 전체 데이터셋을 분석할 필요가 있는 문제에 적합하다.
    
    데이터를 한 번 쓰고 여러 번 읽는 애플리케이션에 적합하다.
    
- RDBMS
    
    상대적으로 작은 양의 데이터를 낮은 지연 시간에 추철하고 변경하기 위해 데이터셋을 색인하기 때문에 특정 쿼리와 데이터 변경에 적합하다.
    
    지속적으로 변경되는 데이터셋에 적합하다.
    

### 1.5.2 그리드 컴퓨팅

고성능 컴퓨팅(HPC)와 그리드 컴퓨팅 커뮤니티는 메시지 전달 인터페이스(MPI)와 같은 API를 이용하여 수년간 대규모 데이터를 처리하고 있다.

대체로 HPC는 SAN으로 연결된 공유 파일시스템에 접근하는 클러스터 머신 여러 대에 작업을 분산시킨다.

> **🤔 HPC (High Performance Computing, 고성능 컴퓨팅)**
매우 크고 복잡한 계산을 빠르게 처리하기 위해 **여러 대의 고성능 컴퓨터(노드)**를 묶어 하나의 거대한 계산 자원처럼 쓰는 기술
> 
> - 병렬 처리 중심: 작업을 여러 조각으로 나눠서 동시에 계산
> - 보통 **슈퍼컴퓨터**나 **대형 클러스터** 형태
> - 빠른 네트워크와 고속 스토리지가 필수

> 🤔 MPI (Message Passing Interface, 메시지 전달 인터페이스)
HPC 환경에서 노드 간 데이터를 주고받기 위해 사용하는 **표준 API**
> 

이런 방식은 계산 중심의 작업에서는 좋은 결과를 얻지만, 계산 노드들이 대용량 데이터에 접근해야 할 때는 네트워크 대역폭 때문에 병목 현상이 생기고 계산 노드가 빈둥거리게 되는 문제가 발생한다.

- HPC 노드들은 보통 SAN이나 공유 파일 시스템에서 저장된 데이터를 가져오는데, 계산 노드가 100대라 해도 결국 저장소와 연결된 네트워크 대역폭을 나눠 사용해야 한다.
- 만약 100대가 동시에 대용량 데이터를 읽으려고 하면, 네트워크 속도(파이프 크기)가 한계에 부딪혀 전송 속도가 느려진다.

하둡은 가능하면 계산 노드에 데이터를 함께 배치한다.

따라서 데이터가 로컬에 있기 때문에 접근도 빠를 수밖에 없다. ⇒ `데이터 지역성`

이러한 특성이 하둡에서 데이터 처리의 핵심이고, 좋은 성능을 내는 이유다.

대규모 분산 컴퓨팅에서 수많은 프로세스를 조율하는 것은 엄청난 과제다.

가장 어려운 점은 원격 프로세스가 실패했는지 정상인지 알 수 없을 때와 같은 부분 실패에 현명하게 대처하는 것과 전체적인 계산의 진행을 이어가는 것이다.

하지만 맵리듀스와 같은 분산 처리 프레임워크는 실패한 태스크를 자동으로 감지하여 장애가 없는 머신에 다시 배치하도록 구현되어 있기 때문에 개발자는 실패에 대해 크게 고민하지 않아도 된다.

이는 맵리듀스가 태스크 간의 상호 의존성이 없는 `비공유 아키텍쳐`기 때문이다.